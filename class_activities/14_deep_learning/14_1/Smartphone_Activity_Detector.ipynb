{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Smartphone Activity Detector\n",
    "\n",
    "In this activity, you will train a neural network to use smartphone data to predict the activity of the user. \n",
    "\n",
    "This dataset has already been separated into input features and target activities. Additional information on the dataset can be found here. \n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/Smartphone-Based+Recognition+of+Human+Activities+and+Postural+Transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing\n",
    "\n",
    "Prepare the data for the neural network. This includes splitting the data into a training and testing dataset, Scaling the data, and encoding the categorical target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.043580 -0.005970 -0.035054 -0.995381 -0.988366 -0.937382 -0.995007   \n",
       "1  0.039480 -0.002131 -0.029067 -0.998348 -0.982945 -0.971273 -0.998702   \n",
       "2  0.039978 -0.005153 -0.022651 -0.995482 -0.977314 -0.984760 -0.996415   \n",
       "3  0.039785 -0.011809 -0.028916 -0.996194 -0.988569 -0.993256 -0.996994   \n",
       "4  0.038758 -0.002289 -0.023863 -0.998241 -0.986774 -0.993115 -0.998216   \n",
       "\n",
       "        7         8         9    ...       551       552       553       554  \\\n",
       "0 -0.988816 -0.953325 -0.794796  ... -0.012236 -0.314848 -0.713308 -0.112754   \n",
       "1 -0.983315 -0.974000 -0.802537  ...  0.202804 -0.603199 -0.860677  0.053477   \n",
       "2 -0.975835 -0.985973 -0.798477  ...  0.440079 -0.404427 -0.761847 -0.118559   \n",
       "3 -0.988526 -0.993135 -0.798477  ...  0.430891 -0.138373 -0.491604 -0.036788   \n",
       "4 -0.986479 -0.993825 -0.801982  ...  0.137735 -0.366214 -0.702490  0.123320   \n",
       "\n",
       "        555       556       557       558       559       560  \n",
       "0  0.030400 -0.464761 -0.018446 -0.841559  0.179913 -0.051718  \n",
       "1 -0.007435 -0.732626  0.703511 -0.845092  0.180261 -0.047436  \n",
       "2  0.177899  0.100699  0.808529 -0.849230  0.180610 -0.042271  \n",
       "3 -0.012892  0.640011 -0.485366 -0.848947  0.181907 -0.040826  \n",
       "4  0.122542  0.693578 -0.615971 -0.848164  0.185124 -0.037080  \n",
       "\n",
       "[5 rows x 561 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>551</th>\n      <th>552</th>\n      <th>553</th>\n      <th>554</th>\n      <th>555</th>\n      <th>556</th>\n      <th>557</th>\n      <th>558</th>\n      <th>559</th>\n      <th>560</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.043580</td>\n      <td>-0.005970</td>\n      <td>-0.035054</td>\n      <td>-0.995381</td>\n      <td>-0.988366</td>\n      <td>-0.937382</td>\n      <td>-0.995007</td>\n      <td>-0.988816</td>\n      <td>-0.953325</td>\n      <td>-0.794796</td>\n      <td>...</td>\n      <td>-0.012236</td>\n      <td>-0.314848</td>\n      <td>-0.713308</td>\n      <td>-0.112754</td>\n      <td>0.030400</td>\n      <td>-0.464761</td>\n      <td>-0.018446</td>\n      <td>-0.841559</td>\n      <td>0.179913</td>\n      <td>-0.051718</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.039480</td>\n      <td>-0.002131</td>\n      <td>-0.029067</td>\n      <td>-0.998348</td>\n      <td>-0.982945</td>\n      <td>-0.971273</td>\n      <td>-0.998702</td>\n      <td>-0.983315</td>\n      <td>-0.974000</td>\n      <td>-0.802537</td>\n      <td>...</td>\n      <td>0.202804</td>\n      <td>-0.603199</td>\n      <td>-0.860677</td>\n      <td>0.053477</td>\n      <td>-0.007435</td>\n      <td>-0.732626</td>\n      <td>0.703511</td>\n      <td>-0.845092</td>\n      <td>0.180261</td>\n      <td>-0.047436</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.039978</td>\n      <td>-0.005153</td>\n      <td>-0.022651</td>\n      <td>-0.995482</td>\n      <td>-0.977314</td>\n      <td>-0.984760</td>\n      <td>-0.996415</td>\n      <td>-0.975835</td>\n      <td>-0.985973</td>\n      <td>-0.798477</td>\n      <td>...</td>\n      <td>0.440079</td>\n      <td>-0.404427</td>\n      <td>-0.761847</td>\n      <td>-0.118559</td>\n      <td>0.177899</td>\n      <td>0.100699</td>\n      <td>0.808529</td>\n      <td>-0.849230</td>\n      <td>0.180610</td>\n      <td>-0.042271</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.039785</td>\n      <td>-0.011809</td>\n      <td>-0.028916</td>\n      <td>-0.996194</td>\n      <td>-0.988569</td>\n      <td>-0.993256</td>\n      <td>-0.996994</td>\n      <td>-0.988526</td>\n      <td>-0.993135</td>\n      <td>-0.798477</td>\n      <td>...</td>\n      <td>0.430891</td>\n      <td>-0.138373</td>\n      <td>-0.491604</td>\n      <td>-0.036788</td>\n      <td>-0.012892</td>\n      <td>0.640011</td>\n      <td>-0.485366</td>\n      <td>-0.848947</td>\n      <td>0.181907</td>\n      <td>-0.040826</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.038758</td>\n      <td>-0.002289</td>\n      <td>-0.023863</td>\n      <td>-0.998241</td>\n      <td>-0.986774</td>\n      <td>-0.993115</td>\n      <td>-0.998216</td>\n      <td>-0.986479</td>\n      <td>-0.993825</td>\n      <td>-0.801982</td>\n      <td>...</td>\n      <td>0.137735</td>\n      <td>-0.366214</td>\n      <td>-0.702490</td>\n      <td>0.123320</td>\n      <td>0.122542</td>\n      <td>0.693578</td>\n      <td>-0.615971</td>\n      <td>-0.848164</td>\n      <td>0.185124</td>\n      <td>-0.037080</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 561 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "# Read the input features into `X`\n",
    "X = pd.read_csv(Path(\"./Resources/features.csv\"), header=None)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   activity\n",
       "0  standing\n",
       "1  standing\n",
       "2  standing\n",
       "3  standing\n",
       "4  standing"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>activity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>standing</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>standing</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>standing</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>standing</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>standing</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "# Read the target values into `y`\n",
    "y = pd.read_csv(Path(\"./Resources/target.csv\"))\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "standing              1423\n",
       "laying                1413\n",
       "sitting               1293\n",
       "walking               1226\n",
       "walking_upstairs      1073\n",
       "walking_downstairs     987\n",
       "stand_to_lie            90\n",
       "sit_to_lie              75\n",
       "lie_to_sit              60\n",
       "lie_to_stand            57\n",
       "stand_to_sit            47\n",
       "sit_to_stand            23\n",
       "Name: activity, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "y.activity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the training and testing input features using StandardScaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "# Apply One-hot encoding to the target labels\n",
    "enc = OneHotEncoder()\n",
    "\n",
    "class_values = y[\"activity\"].values.reshape(-1, 1)\n",
    "enc.fit(class_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array(['laying', 'lie_to_sit', 'lie_to_stand', 'sit_to_lie',\n",
       "        'sit_to_stand', 'sitting', 'stand_to_lie', 'stand_to_sit',\n",
       "        'standing', 'walking', 'walking_downstairs', 'walking_upstairs'],\n",
       "       dtype=object)]"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "type(enc.categories_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  laying lie_to_sit lie_to_stand sit_to_lie sit_to_stand sitting stand_to_lie  \\\n",
       "0    0.0        0.0          0.0        0.0          0.0     0.0          0.0   \n",
       "1    0.0        0.0          0.0        0.0          0.0     0.0          0.0   \n",
       "2    0.0        0.0          0.0        0.0          0.0     0.0          0.0   \n",
       "3    0.0        0.0          0.0        0.0          0.0     0.0          0.0   \n",
       "4    0.0        0.0          0.0        0.0          0.0     0.0          0.0   \n",
       "\n",
       "  stand_to_sit standing walking walking_downstairs walking_upstairs  \n",
       "0          0.0      1.0     0.0                0.0              0.0  \n",
       "1          0.0      1.0     0.0                0.0              0.0  \n",
       "2          0.0      1.0     0.0                0.0              0.0  \n",
       "3          0.0      1.0     0.0                0.0              0.0  \n",
       "4          0.0      1.0     0.0                0.0              0.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>laying</th>\n      <th>lie_to_sit</th>\n      <th>lie_to_stand</th>\n      <th>sit_to_lie</th>\n      <th>sit_to_stand</th>\n      <th>sitting</th>\n      <th>stand_to_lie</th>\n      <th>stand_to_sit</th>\n      <th>standing</th>\n      <th>walking</th>\n      <th>walking_downstairs</th>\n      <th>walking_upstairs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "# Encode cateogories\n",
    "class_encoded = enc.transform(class_values).toarray()\n",
    "class_encoded_df = pd.DataFrame(class_encoded, columns=enc.categories_)\n",
    "class_encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "class_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the first layer where the input dimensions are the 561 columns of the training data\n",
    "number_inputs = 561\n",
    "number_hidden_nodes = 6\n",
    "model.add(Dense(units=number_hidden_nodes, activation=\"relu\", input_dim=number_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output layer has 12 columns that are one-hot encoded\n",
    "y_train.activity.value_counts()\n",
    "number_outputs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add output layer using 12 output nodes. \n",
    "# HINT: Use `softmax` as the activation \n",
    "number_classes = 1\n",
    "\n",
    "model.add(Dense(units=number_outputs, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model using categorical_crossentropy for the loss function, the adam optimizer,\n",
    "# and add accuracy to the training metrics\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_12 (Dense)             (None, 6)                 3372      \n_________________________________________________________________\ndense_13 (Dense)             (None, 12)                84        \n=================================================================\nTotal params: 3,456\nTrainable params: 3,456\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 5825\n  y sizes: 7767\nMake sure all arrays contain the same number of samples.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-8420a123250d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Use the training data to fit (train) the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# @NOTE: Experiment with the number of training epochs to find the minimum iterations required to achieve a good accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel_fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_encoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1062\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1064\u001b[1;33m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m       \u001b[1;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1112\u001b[1;33m         model=model)\n\u001b[0m\u001b[0;32m   1113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[1;31m# If batch_size is not passed but steps is, calculate from the input data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1527\u001b[0m           label, \", \".join(str(i.shape[0]) for i in nest.flatten(single_data)))\n\u001b[0;32m   1528\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1529\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 5825\n  y sizes: 7767\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "# Use the training data to fit (train) the model\n",
    "# @NOTE: Experiment with the number of training epochs to find the minimum iterations required to achieve a good accuracy\n",
    "model_fit = model.fit(X_train_scaled, class_encoded, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the testing data\n",
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predicted = model.predict(X_test_scaled)\n",
    "predicted = enc.inverse_transform(predicted).flatten().tolist()\n",
    "results = pd.DataFrame({\n",
    "    \"Actual\": y_test.activity.values,\n",
    "    \"Predicted\": predicted\n",
    "})\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(results.Actual, results.Predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('pyvizenv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a3d83b3bb7a284bee10f9f12036d8156a359fe396990fa5060485ae25a957122"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}